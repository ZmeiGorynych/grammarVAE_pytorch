{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAF+UlEQVR4nO3d3W4aSRhFUTPK+79y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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x300 at 0x7F8BDDF05A20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import MolToImage\n",
    "\n",
    "MolToImage(Chem.MolFromSmiles('c1nccc2n1ccc2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/250k_rndm_zinc_drugs_clean.smi'\n",
    "\n",
    "with open(fname) as f:\n",
    "    smiles = f.readlines()\n",
    "\n",
    "for i in range(len(smiles)):\n",
    "    smiles[i] = smiles[i].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load model parameters from  ../pretrained/my_molecules.mdl\n",
      "Success!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ba9f262ee71e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgrammar_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrammar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZincGrammarModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrammar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c1nccc2n1ccc2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnew_smile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrammar_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/shared/GitHub/grammarVAE_pytorch/models/grammar_ed_models.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# TODO: WHY ndim = 2?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0munmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mX_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_using_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munmasked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Convert from one-hot to sequence of production rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/shared/GitHub/grammarVAE_pytorch/models/model_grammar_pytorch.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# TODO: should actually be handling single vectors, not batches, dependent on dim?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from grammarVAE_pytorch.models import grammar_ed_models as grammar_model\n",
    "\n",
    "# We load the auto-encoder\n",
    "grammar_weights = '../pretrained/my_molecules.mdl'\n",
    "grammar_model = grammar_model.ZincGrammarModel(grammar_weights)\n",
    "z = grammar_model.encode(['c1nccc2n1ccc2'])\n",
    "new_smile = grammar_model.decode(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
